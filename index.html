<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jun Li</title>
  
  <meta name="author" content="Jun Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!--   <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jun Li 「李骏」</name>
              </p>
              <p style="text-align:center"><font color="red"><em><strong>I will apply for PhD programs starting in 2024 Fall.</strong></em></font>
              </p>
              <p>I am a fourth-year undergraduate student at <a href="http://global.jlu.edu.cn/"> Jilin University</a>. Previously, I worked with <a href="https://hsd1503.github.io/">  Shenda Hong, PhD</a>, in national institute of health data science at <a href="https://www.nihds.pku.edu.cn/en/"> Peking University</a>. Currently, I'm a research intern in Department of Neurology, <a href="https://www.bidmc.org/"> Beth Israel Deaconess Medical Center</a> , <a href="https://hms.harvard.edu/"> Harvard Medical School</a> , working with <a href="https://scholar.google.com/citations?user=helCG6IAAAAJ&hl=en">  M Brandon Westover, MD, PhD</a>.
              </p>
              <p>Email: lijun2020 [AT] mails.jlu.edu.cn
              </p>
<!--                -->
              
<!--               <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <br>
<!--               <p style="text-align:center">
                  I'm looking for summer research opportunities in 2021!
              </p> -->
              <p style="text-align:center">
                <!-- <a href="mailto:tairanhe1999@gmail.com">Email</a> &nbsp/&nbsp -->
                <a href="data/JunLiCV_20231026.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=dfpJWQYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/NickLJLee">GitHub</a>

<!--                 <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
<!--                 <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a>  --><!-- &nbsp/&nbsp -->
<!--                 <a href="https://twitter.com/jon_barron">Twitter</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JunLi.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JunLi.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Topics</heading>
              <p>
                My research focuses on the intersection of <u>artificial intelligence</u>, <u>computational clinical research</u>, and <u>temporal medical data</u>, with a particular interest in <u>multimodal learning for healthcare</u> and <u>physiological signal analysis</u>. The goal of my research is to investigate how machine learning frameworks can be used to aid, understand and integrate multimodal clinical medical data.
                <br>

<!--                 Currently, I concetrate on the data-driven RL tasks (e.g., <b>imitation learning</b> and <b>batch reinforcement learning</b>) and <b>representation learning</b> in RL.  -->

<!--                 I keep reading an inspiring paper every day, and share my understanding and notes in the  <a href="https://www.zhihu.com/column/c_1300374076980932608"> Zhihu column</a>. -->
                <!-- Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              (* equal contribution)
            </td>
          </tr>
          <tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2303.12311" id="SafeRL-Survey">
                <papertitle>Frozen Language Model Helps ECG Zero-Shot Learning</papertitle>
              </a>
              <br>
              <b>Jun Li*</b>, Che Liu*, Sibo Cheng, Rossella Arcucci, Shenda Hong
<!--               <br> -->
<!--               <em>Conference on Neural Information Processing Systems (NeurIPS)</em>,&nbsp;2022&nbsp; -->
<!--               Conference on Neural Information Processing Systems (NeurIPS) DeepRL Workshop, 2022  -->
              <br>
              <em>Medical Image in Deep Learning (MIDL)</em>, &nbsp;2023,<b style="color: red;">(Oral Presentaion)</b>
              &nbsp;
              <br>
              <a href="https://arxiv.org/abs/2303.12311">ArXiv</a>
              <img src="images/Fig1.png" style="float: right; width: 100%; height: auto;">
              <br>
              <font color='gray'>The electrocardiogram (ECG) is one of the most commonly used non-invasive, convenient medical monitoring tools that assist in the clinical diagnosis of heart diseases. Recently, deep learning (DL) techniques, particularly self-supervised learning (SSL), have demonstrated great potential in the classification of ECG. SSL pre-training has achieved competitive performance with only a small amount of annotated data after fine-tuning. However, current SSL methods rely on the availability of annotated data and are unable to predict labels not existing in fine-tuning datasets. To address this challenge, we propose Multimodal ECG-Text Self-supervised pre-training (METS), the first work to utilize the auto-generated clinical reports to guide ECG SSL pre-training. We use a trainable ECG encoder and a frozen language model to embed paired ECG and automatically machine-generated clinical reports separately. The SSL aims to maximize the similarity between paired ECG and auto-generated report while minimize the similarity between ECG and other reports. In downstream classification tasks, METS achieves around 10% improvement in performance without using any annotated data via zero-shot classification, compared to other supervised and SSL baselines that rely on annotated data. Furthermore, METS achieves the highest recall and F1 scores on the MIT-BIH dataset, despite MIT-BIH containing different classes of ECG compared to the pre-trained dataset. The extensive experiments have demonstrated the advantages of using ECG-Text multimodal self-supervised learning in terms of generalizability, effectiveness, and efficiency.</font>
             <!--- <div style="text-align:center;">
                <img src="images/Fig1.png" style="width:100%; max-width:800px; height:auto;">
              </div>-->

              <div style="clear: both;"></div>
<!--               <p>This paper subsumes our CVPR 2014 paper.</p> -->
            </td>
          </tr>
        </tbody></table>

<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px 20px 0px 20px;width:25%;vertical-align:middle">
                <img src="images/wkfgicon.png" width="160" height="160"></td>
              <td style="width:25%; vertical-align:middle;">
                <img src="images/wkfgicon.png" width="160" height="160" style="margin-top: 20px;">
                <img src="images/wkfgicon.png" width="160" height="160" style="margin-top: 20px;">
              </td>
              <td style="width:25%; vertical-align:middle;">
              </td>
              <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                <a href="https://www.techrxiv.org/articles/preprint/EEG_Detection_and_Prediction_of_Freezing_of_Gait_in_Parkinson_s_Disease_Based_on_Spatiotemporal_Coherent_Modes/21829530" id="PatchAIL">
              </td>
            </tr>
          </tbody>
        </table>-->
        
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>

              
            <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
              <a href="https://www.techrxiv.org/articles/preprint/EEG_Detection_and_Prediction_of_Freezing_of_Gait_in_Parkinson_s_Disease_Based_on_Spatiotemporal_Coherent_Modes/21829530" id="PatchAIL">
                <papertitle>EEG Detection and Prediction of Freezing of Gait in Parkinson's Disease Based on Spatiotemporal Coherent Modes

                </papertitle>
              </a>
              <br>
              <b>Jun Li</b>, Yuzhu Guo
<!--               <br> -->
<!--               <em>Conference on Neural Information Processing Systems (NeurIPS)</em>,&nbsp;2022&nbsp; -->
<!--               Conference on Neural Information Processing Systems (NeurIPS) DeepRL Workshop, 2022  -->
              <br>
              <em>Submitted to IEEE Journal of Biomedical and Health Informatics (JBHI), Under the second round of minor revision </em>, &nbsp;2023&nbsp;
              <br>
              <a href="https://www.techrxiv.org/articles/preprint/EEG_Detection_and_Prediction_of_Freezing_of_Gait_in_Parkinson_s_Disease_Based_on_Spatiotemporal_Coherent_Modes/21829530">TechRxiv</a>

<!--               &nbsp;/&nbsp;
              <a href="https://github.com/oscardhc/Forum"> iOS Code</a>
              &nbsp;/&nbsp;
              <a href="http://wukefenggao.cn"> Project Page</a>
              &nbsp;/&nbsp;
              <a href="https://www.bilibili.com/video/BV1Rp4y187ZJ"> Farewell Video</a> -->
              <!-- <font color="red"><em><strong>(oral)</strong></em></font> -->
<!--               <em>TPAMI</em>, 2017 -->
<!--               <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a> -->
<!--               <p></p> -->
<img src="images/DMD-ACSP.png" style="float: right; width: 100%; height: auto;">
              <br>
              <font color='gray'>Freezing of gait (FOG) in the Parkinson's disease has a complex mechanism and is closely related brain activities. Timely prediction of FOG is crucial to fall prevention and injury avoidance. Traditional electroencephalogram (EEG) processing methods extract time, spatial, frequency, or phase information separately and use them or their combinations, which fragment the connections among these heterogeneous features and cannot completely characterize the whole brain dynamics during the occurrence of FOG. In this study, dynamic spatiotemporal coherent modes during the FOG were studied and the associated FOG detection and prediction were proposed. For capturing the changes of the brain, dynamic mode decomposition (DMD) method was applied. Dynamic changes of the spatiotemporal modes in both amplitude and phase of motor-related frequency bands were analyzed and an analytic common spatial patterns (ACSP) was used as a spatial filter to extract the essential differences among the normal, freezing and transitional gaits.  The proposed method was verified in practical clinical data. Results showed that in the detection task, the DMD-ACSP achieved an accuracy of 89.1 ± 3.6% and sensitivity of 83.5 ± 4.3%, respectively. In the prediction task, an 83.5 ± 3.2% accuracy and 86.7 ± 7.8% sensitivity were achieved.  Comparative studies showed that the DMD-ACSP method significantly improves the FOG detection and prediction performance. Moreover, the DMD-ACSP reveals the spatial patterns of dynamic brain functional connectivity which best discriminate the different gaits.  The spatiotemporal coherent modes may provide useful indication for transcranial magnetic stimulation neuromodulation in medical practices. </font>
<!--               <p>This paper subsumes our CVPR 2014 paper.</p> -->
<div style="clear: both;"></div>

            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
          <tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:0px 20px 0px 20px;width:100%;vertical-align:middle"> 
              <!-- padding 上 右 下 左 -->
              <!--- <a href="http://wukefenggao.cn" id="wkfg"> -->
                <papertitle>JiZou Intelligence —— Intelligent Piano Education System 「极奏智能」</papertitle>
              </a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 0px 20px;width:25%;vertical-align:middle"><img src="images/jzzn.png" width="160" height="160"></td>
            <td width="75%" valign="center">
              <br>
              <a href="https://www.bilibili.com/video/BV1gf4y1T7yJ"> Video</a>
              <br>
              <p>An Intelligent Piano Education System based on the multi-modal deep learning. Computer vision, Music AI and photoelectric sensors are used to improve the quality of piano teaching.
                </p>
              <p>Committed to promoting piano education to children who are not rich but love piano.</p>
            </td>
          </tr>
        </tbody></table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
            </td>
          </tr>
          <tr>
        </tbody></table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
              <a href="https://bdsp-core.github.io/"> Clinical Data Animation Center</a>, <b>Harvard Medical School, Beth Israel Deaconess Medical Center</b>
              <br>
              Summer Intern • Jul 2023 - Present
              <br>
              Advisor: <a href="https://scholar.google.com/citations?user=helCG6IAAAAJ&hl=en"> Prof. M.Brandon Westover</a>
              </br>
            </td>
            <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img src="images/Harvardlogo.png" width="75" height="75"></td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
              <a href="https://www.nihds.pku.edu.cn/en/"> Hong Lab</a>, <b>Peking University</b>
              <br>
              Research Intern • Nov 2022 - Present
              <br>
              Advisor: <a href="https://hsd1503.github.io/"> Prof. Shenda Hong</a>
              </br>
            </td>
            <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img src="images/PKUlogo.png" width="75" height="75"></td>
          </tr>
        </tbody></table>

        


<!--         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
              <a href="http://wukefenggao.cn" id="wkfg">
                <papertitle>SJTU Anonymous Forum 「无可奉告」</papertitle>
              </a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/wkfgicon.png" width="160" height="160"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, CVPR 2021</a>
              <br><br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br><br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
        </tbody></table> -->




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <br>
                                    <div>
                                      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=hAzEpSncsi9EIBfN_v5ccBJo3auRn5fg1iHkyeRpnRY"></script>
                                        <!-- <a target="_top" href="http://clustrmaps.com/site/1acpn?utm_source=widget&amp;utm_campaign=widget_ctr" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 300px;">
 -->                               </div>
                                </td>
                            </tr>
                        </tbody>
        </table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px">
                <p font-size:small;="">
                    <br>
                    <br>
                    </p><div style="float:left;">
                        Updated at Oct. 2023
                    </div>
                    <div style="float:right;">
                        Thanks <a href="https://jonbarron.info">Jon Barron</a> for this amazing template
                    </div>
                    <br>
                    <br>        
                <p></p>                           
            </td>
          </tr>
        </tbody></table>



      </td>
    </tr>
  </table>
</body>

</html>
